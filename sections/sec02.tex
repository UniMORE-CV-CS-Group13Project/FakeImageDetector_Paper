\section{Related Work}\label{sec:RelatedWork}
The DeepFake Detection problem has been addressed with different methodologies. Approaches based on the spatial domain use standard CNNs (e.g. ResNet\cite{he2015deepresiduallearningimage}, EfficientNet\cite{tan2020efficientnetrethinkingmodelscaling}) trained on huge datasets of RGB images \cite{r√∂ssler2019faceforensicslearningdetectmanipulated}. Although effective, these models tend not to be robust on specific visual artifacts (e.g. blurred background, eyes asymmetries, image compression). \par
To overcome these limitations, more recent approaches focus on the frequency domain. Studies such as those by Wang et al.\cite{wang2020cnngeneratedimagessurprisinglyeasy}, Frank et al.\cite{frank2020leveragingfrequencyanalysisdeep} and Durall et al.\cite{durall2020watchupconvolutioncnnbased} have shown that analysis conducted in the frequency domain can make the network detect hidden periodic patterns invisible to the human eye. \par
More recently, efforts have focused on improving cross-model generalization. Ojha et al.\cite{ojha2024universalfakeimagedetectors} proposed universal fake image detectors designed to remain effective across multiple and unseen generators. However, these approaches typically frame the task as binary classification, neglecting the problem of source attribution, which is increasingly relevant in accountability-driven scenarios. \par
Our work fits into the frequency-domain paradigm, distinguishing itself by the use of a composite representation of the input that includes not only the magnitude spectrum, but also the phase components (fundamental for the image structure) and the autocorrelation, capturing repetitive patterns in the frequency domain. These features are then processed by a custom convolutional architecture, allowing for both detection of generated images and generator-specific source attribution.