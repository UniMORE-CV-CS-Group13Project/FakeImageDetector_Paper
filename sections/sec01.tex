\section{Introduction}\label{sec:Introduction}
The widely adopted use of Generative models (GANs and Diffusion Models) has made it increasingly difficult to distinguish genuine content from synthetic one just by looking at it. While instruments such as Midjourney or Stable Diffusion offer vast creative possibilities, they also pose critical risks related to disinformation and deepfakes. \par
The adoption of synthetic content in traditional media has already triggered significant public controversy. Major brands such as Coca-Cola and McDonald's have faced strong consumer backlash following the release of advertising campaigns created entirely or partially using artificial intelligence \cite{CocaCola-AI, McDonadlds-AI}. Similar criticism has emerged in other sectors, including publishing, where Tor Books was subject to scrutiny for using generative art on the cover of a novel \cite{Gothikana-AI}, and fashion where Vogue employed artificially generated models in its productions \cite{Forbes-AI}. \par
Even more alarming is the use of these technologies in the development of hyper-realistic deepfakes aimed at fraud or disinformation. A striking example is the recent case involving Brad Pitt, whose likeness was cloned to promote online scams, clearly demonstrating the risks posed by such systems \cite{BradPitt-Scam}. These episodes highlight the need for robust automated solutions for deepfake detection and source attribution, in order to restore human trust in digital visual media. \par
Recent scientific literature suggests that, although generated images may appear flawless in the spatial domain, they often have distinctive fingerprints in the frequency domain. These spectral fingerprints are frequently introduced by architectural components of generative models, such as upsampling operations and convolutional filters. \par
Motivated by these findings, the adopted approach discards the traditional RGB analysis to focus exclusively on the spectral characteristics. This study proposes a personalized CNN (Convolutional Neural Network) that takes as input a four channel tensor, which does not represent the original image in the spatial domain as in traditional approaches, and exploits the Discrete Fourier Transform - thus the frequency domain of the original image - to gather different characteristics of the image itself:
\begin{itemize}
    \item Magnitude of the Discrete Fourier Transform of the Image;
    \item Phase (decomposed in sine and cosine in separate channels) of the Discrete Fourier Transform of the Image;
    \item Autocorrelation of the Image in the frequency domain.
\end{itemize}